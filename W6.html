<!doctype html>
<html>
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
<title>Image Analysis with Fiji</title>
<link rel="stylesheet" href="css/reveal.css">
<link rel="stylesheet" href="css/theme/cci.css">
<link href="https://fonts.googleapis.com/css?family=Poppins" rel="stylesheet">
<!-- Theme used for syntax highlighting of code -->
<link rel="stylesheet" href="lib/css/zenburn.css">
<!-- Printing and PDF exports -->
<script>
var link = document.createElement( 'link' );
link.rel = 'stylesheet';
link.type = 'text/css';
link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
document.getElementsByTagName( 'head' )[0].appendChild( link );
</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
<div class="reveal">
<!-- Header logo -->
<!--img style="position:fixed;top:1em;right:1em;" src="img/logo_cci.png" width="15%"-->
<!-- Slide Title -->
<header style="position: absolute;top: 1em; left: 1em; z-index:10;"></header>




<!-- ---------------------- START OF SLIDES -------------------------- -->
<div class="slides">

<section data-menu-title="Title">
<h1>Tracking and Machine Learning for Pixel Classification</h1>
<h3>Laura Cooper<br>Research Fellow, CAMDU</h3>
<br>
<p>Navigation:
<ul><li> Left/right arrow keys for previous/next slide</li><li>'m' key to get to navigation menu</li><li>Escape for slide overview</li></ul>
</p>
</section>

<!-- ---------------------- APPLICATIONS TRACKING -------------------------- -->

<section data-menu-title="Tracking" data-state="apps1z"><style>.apps1z header:after { content: ""; }</style>
<h1>Applications: Tracking</h1>
<h4>Correlating spatial and temporal phenomena, Feature detection, linkage, gotchas</h4>
</section>
 
<section data-state="apps1"><style>.apps1 header:after { content: "Tracking: Theory"; }</style>
<p>Life exists in the fourth dimension. Tracking allows you to correlate spatial and temporal properties.</p>
<img class="third" src="img-ia/tracks_01.png"/><span>&nbsp;&nbsp;&nbsp;</span><img data-fragment-index="2" class="third fragment" src="img-ia/tracks_02.png"/>
<p data-fragment-index="1" class="fragment">Most partcles look the same! Without any way to identify them, tracking is probabilistic.</p>
</section>

<section data-state="apps1"><style>.apps1 header:after { content: "Tracking: Theory"; }</style>
<p>Tracking has two parts: Feature Identification and Feature Linking</p>
<img class="half" src="img-ia/tracks_03.png"/><img class="half" src="img-ia/tracks_04.png"/>
<p>For every frame, features are detected, typically using a Gaussian-based method (eg. <a href="https://en.wikipedia.org/wiki/Blob_detection#The_difference_of_Gaussians_approach" target="_blank">Laplacian of Gaussian</a>: LoG)</p>
</section>
<section data-state="apps1"><style>.apps1 header:after { content: "Tracking: Theory"; }</style>
<p>Spots can be localised to sub-pixel resolution!</p>
<img class="left half" src="img-ia/tracks_05.png"/>
<p class="right half">Without sub-pixel localisation, the precision of detection is limited to whole pixel values.</p>
</section>
<section data-state="apps1"><style>.apps1 header:after { content: "Tracking: Theory"; }</style>
<p>Feature linkage</p>
<!-- <img class="half" src="img-ia/tracks_06.png"/><br> -->
<img class="half" src="img-ia/tracks_07.png"/>
<p>For each feature, all possible links in the next frame are calculated. This includes the spot disappearing completely.</p>
<img data-fragment-index="1" class="fragment half" src="img-ia/tracks_08.png"/>
<p data-fragment-index="2" class="fragment">A 'cost matrix' is formed to compare the 'cost' of each linkage. This is globally optimised to calculate the lowest cost for all linkages.</p>
</section>
<section data-state="apps1"><style>.apps1 header:after { content: "Tracking: Theory"; }</style>
<!-- <img class="half" src="img-ia/tracks_07.png"/> -->
<p>In the simplest form, a cost matrix will usually consider distance. Many other parameters can be used such as:</p>
<ul>
<li>Intensity</li>
<li>Shape</li>
<li>Quality of fit</li>
<li>Speed</li>
<li>Motion type</li>
</ul>
<p>Which can allow for a more accurate linkage especially in crowded or low S/N environments</p>
</section>

<section data-state="apps2"><style>.apps2 header:after { content: "Tracking: Hands On"; }</style>
<p>Open <a href="material/10-tracks.tif"><code>10-tracks.tif</code></a><br>Hit the arrow to play the movie. Right Click on the arrow to set playback speed</p>
<img class="quart" src="img-ia/tracks_11.png"/>
<p class="fragment">If you're interested in how the dataset was made see <a href="https://bitbucket.org/snippets/davemason/Ke9zz7" target="_blank">this snippet</a></p>
</section>

<section data-state="apps2"><style>.apps2 header:after { content: "Tracking: Hands On"; }</style>
<p>Run <code>[Plugins > Tracking > Trackmate]</code></p>

<img class="half left" src="img-ia/trackmate_01.png"/>

<ul class="half right"><li>Trackmate guides you through tracking using the Next and Prev buttons</li><li>The first dialog lets you select a subset (in space and time) to process. This is handy on large datasets when you want to calculate parameters before processing the whole dataset</li><li>Hit Next, keep the default (LoG) detector then hit Next again to move onto Feature detection.</li></ul>
</section>
<section data-state="apps2"><style>.apps2 header:after { content: "Tracking: Hands On"; }</style>
<img class="left half" src="img-ia/trackmate_02.png"/>
<ul class="half right"><li>Enter a Blob Diameter of 2 (note the scaled units)</li><li>Hit preview. Without any threshold, all the background noise is detected as features</li><li>Add a threshold of 0.1 and hit Preview again.</li></ul>

<p class="fragment clear">Generally your aim should be to provide the minimum threshold that removes all noise. Slide the navigation bar, then hit Preview to check out a few other timepoints.</p>
</section>
<section data-state="apps2"><style>.apps2 header:after { content: "Tracking: Hands On"; }</style>
<img class="left half" src="img-ia/trackmate_04.png"/>
<p class="half right">Hit next, accepting defaults until you reach 'Set Filters on Spots'</p>
</section>
<section data-state="apps2"><style>.apps2 header:after { content: "Tracking: Hands On"; }</style>
<img class="left half" src="img-ia/trackmate_05.png"/>
<ul class="half right">
<li>Hit next, accepting defaults until you reach 'Settings for Simple LAP tracker'</li>
<li>Set the distances to 5 and hit Next</li>
<li>You have tracks!</li>
</ul>
</section>
<section data-state="apps2"><style>.apps2 header:after { content: "Tracking: Hands On"; }</style>
<img class="left half" src="img-ia/trackmate_05.png"/>
<div class="half right">
<p class="fragment"><code>Linking Max Distance</code> Sets a 'search radius' for linkage</p>
<img class="fragment" src="img-ia/tracks_09.png"/>
<p class="fragment"><code>Gap-closing Max Frame Gap</code> Allows linkages to be found in non-adjacent frames</p>
<img class="fragment" src="img-ia/tracks_10.png"/>
<p class="fragment"><code>Gap-closing Max Distance</code> Limits search radius in non-adjacent frames</p>
</div>
</section>

<section data-state="apps2"><style>.apps2 header:after { content: "Tracking: Hands On"; }</style>
<p>Common outputs from Trackmate: (1) Tracking data</p>
<img class="left half" src="img-ia/trackmate_06.png"/>
<img class="right half" src="img-ia/trackmate_08.png"/>
<p>Click 'Tracks' or 'Spots' to view the analysis.</p>
</section>
<section data-state="apps2"><style>.apps2 header:after { content: "Tracking: Hands On"; }</style>
<p>Common outputs from Trackmate: (2) Movies!</p>
<img class="left half" src="img-ia/trackmate_07.png"/>
<img class="right third" src="img-ia/trackmate_09.gif"/>
<div class="clear"></div>
<p>You may have to adjust the display options to get the tracks drawing the way you want (try "Local Backwards")</p>
</section>

<section data-state="apps3"><style>.apps3 header:after { content: "Tracking: Common Problems"; }</style>
<p>While simple, Tracking is not to be taken on lightly!</p>
<ul>
<li>For the best results make sure the inter-particle distance is greater than the frame-to-frame movement. If not, try to increase resolution (more pixels) or decrease interval (more frames)</li>
<li>The search radius increases processing time with HUGE datasets but in most case, has little effect on processing time. Remember that closer particles will still be linked preferably if possible.</li>
<li>Keep it simple! Unless you have problems with noise, blinking, focal shifts and similar, do not introduce gap closing as this may lead to false-linkages</li>
<li>'Simple LAP tracker' does not include merge/spliting events, however Trackmate ships with the more complex 'LAP Tracker' which can handle merge/splitting events (but keep in mind your system!)</li>
<li>Quality control! Look at your output carefully and make sure you're not getting 'jumps' where one particle is linked to another incorrectly</li>
</ul>
</section>

<!------------------MACHINE LEARNING---------------->

<section data-menu-title="Machine Learning" data-state="ml1z"><style>.ml1z header:after { content: ""; }</style>
<h1>Machine Learning</h1>
<p>
<ul>
<li>Algorithms designed to find patterns in data</li>
<li>Training (supervised learning) takes a set of input data and it's known outputs and trains a model to predict the output for new data</li>
<li>Classfication models separate input data into categories</li>
</ul> 
</p>
</section>

<section data-state="ml1"><style>.ml1 header:after { content: "Trainable Weka Segmentation"; }</style>
<p>
<ul>
<li><a href="https://imagej.net/plugins/tws/">Trainable Weka Segmentation Fiji Plugin</a></li>
<li>Combines a collection of machine learning algorithms with selected image features to produce segmentations</li>
<li>Other software options include:
<ul>
<li><a href=https://www.ilastik.org/index.html>ilastik</a></li>
<li><a href=https://imagej.net/plugins/labkit/>LabKit</a></li> 
<li><a href=https://github.com/saalfeldlab/paintera>Paintera</a></li>
</ul> 
</ul> 
</p>
</section>

<section data-state="ml1"><style>.ml1 header:after { content: "Trainable Weka Segmentation"; }</style>
<p>
<ul>
<li>Download <a href="material/BBBC008_partial.zip">this folder</a> and unzip. This is a subset of BBBC008 from the <a href="https://data.broadinstitute.org/bbbc/BBBC008/" target="_blank">Broad Bioimage Benchmark Collection</a> (same dataset as used in Workshop 2)</li>
<li>In Fiji, <code>[Plugins > Segmentation > Trainable Weka Segmentation]</code>, select one of the images to open.</li>
</ul> 
</p>
</section>

<section data-state="ml1"><style>.ml1 header:after { content: "Trainable Weka Segmentation"; }</style>
<p>
<img class="left half" src="img-lc/weka/train1.png"/>
<ul class="right half">
<li>Click and drag to draw on the image</li>
<li>Draw a line in the background (dark area) and click <code>Add to class 1</code> (on the right)</li>
<li>Draw a line in one or two of the nuclei (light area) and click <code>Add to class 2</code></li>
<li>Click <code>Train classifier</code> (on the left)</li>
</ul> 
</p>
</section>

<section data-state="ml1"><style>.ml1 header:after { content: "Trainable Weka Segmentation"; }</style>
<p>
<img class="left half" src="img-lc/weka/train2.png"/>
<ul class="right half">
<li>Add more labels and retrain the classifier, to improve the result</li>
<li>[Optional] Click <code>Settings</code> and select/deselect different "Training features". Retrain the classifier to see how the different features change the result. For more information about each feature, visit the <a href="https://imagej.net/plugins/tws/">Plugin webpage</a></li>
<li>When you are happy with the result, click <code>Apply classifier</code> and select a different image from the data set. Does the classifier work well for this image too?</li>
<li>Click <code>Save data</code> and save the data.arff file</li>
</ul> 
</p>
</section>

<section data-state="ml1"><style>.ml1 header:after { content: "Trainable Weka Segmentation"; }</style>
<p>
<ul>
<li>Close the Trainable Weka Segmentation Window and any other open image windows</li>
<li><code>[Plugins > Segmentation > Trainable Weka Segmentation]</code> and select another image to open.</li>
<li>Click <Load data> and open the data.arff file</li>
<li>Click <code>Train classifier</code>. This will apply the classifier from the previous image</li>
<li>Add more labels and click <code>Train classifier</code> again. This allows you to train on multiple images</li>
</ul> 
</p>
</section>

<section data-state="ml1"><style>.ml1 header:after { content: "Machine Learning"; }</style>
<p>
<ul>
<li>Machine learning can also be used for:
<ul>
<li>Denoising</li>
<li>Isotropic Reconstruction</li>
<li>Surface Projection</li>
</ul>
<li>See <a herf=https://csbdeep.bioimagecomputing.com/>CSBDeep</a> for examples</li>
<li>Training a model can be very time consuming, it can require a lot of user input and computing time. Using a Graphical Processing Unit (GPU) rather than the Central Processing Unit (CPU) can speed up the processing time.</li>
</ul> 
</p>
</section>

</div> <!-- ---------------------- END OF SLIDES -------------------------- -->


</div>
<!-- Footer -->
<img style="position:fixed;bottom:1em;right:1em;" src="img/logo_WMS.jpg" width="10%">
<!--img style="position:fixed;bottom:1em;left:1em;" src="img/logo_tw.png" width="20%"-->
</div>

<script src="lib/js/head.min.js"></script>
<script src="js/reveal.js"></script>

<script>
// More info about config & dependencies:
// - https://github.com/hakimel/reveal.js#configuration
// - https://github.com/hakimel/reveal.js#dependencies
Reveal.initialize({
    controls: false,
	slideNumber: true, //-- Added for development
dependencies: [
{ src: 'plugin/markdown/marked.js' },
{ src: 'plugin/markdown/markdown.js' },
{ src: 'plugin/notes/notes.js', async: true },
{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
{ src: 'plugin/menu/menu.js' }
],
menu: {
hideMissingTitles: true,
themes: false,
transitions: false,
//markers: true,
numbers: true,
openButton: false,
titleSelector: 'span.menu-title'

}
});
</script>
</body>
</html>
